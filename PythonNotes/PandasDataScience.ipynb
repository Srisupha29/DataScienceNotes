{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "893294ff-5308-42ce-8010-6277a7d801d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a2869e-145e-44d5-994f-99e1fe8e6ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete_id</th>\n",
       "      <th>name</th>\n",
       "      <th>born_date</th>\n",
       "      <th>born_city</th>\n",
       "      <th>born_region</th>\n",
       "      <th>born_country</th>\n",
       "      <th>NOC</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>died_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jean-François Blanchy</td>\n",
       "      <td>1886-12-12</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Gironde</td>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Arnaud Boetsch</td>\n",
       "      <td>1969-04-01</td>\n",
       "      <td>Meulan</td>\n",
       "      <td>Yvelines</td>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "      <td>183.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jean Borotra</td>\n",
       "      <td>1898-08-13</td>\n",
       "      <td>Biarritz</td>\n",
       "      <td>Pyrénées-Atlantiques</td>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "      <td>183.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1994-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jacques Brugnon</td>\n",
       "      <td>1895-05-11</td>\n",
       "      <td>Paris VIIIe</td>\n",
       "      <td>Paris</td>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "      <td>168.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1978-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Albert Canet</td>\n",
       "      <td>1878-04-17</td>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1930-07-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   athlete_id                   name   born_date    born_city  \\\n",
       "0           1  Jean-François Blanchy  1886-12-12     Bordeaux   \n",
       "1           2         Arnaud Boetsch  1969-04-01       Meulan   \n",
       "2           3           Jean Borotra  1898-08-13     Biarritz   \n",
       "3           4        Jacques Brugnon  1895-05-11  Paris VIIIe   \n",
       "4           5           Albert Canet  1878-04-17   Wandsworth   \n",
       "\n",
       "            born_region born_country     NOC  height_cm  weight_kg   died_date  \n",
       "0               Gironde          FRA  France        NaN        NaN  1960-10-02  \n",
       "1              Yvelines          FRA  France      183.0       76.0         NaN  \n",
       "2  Pyrénées-Atlantiques          FRA  France      183.0       76.0  1994-07-17  \n",
       "3                 Paris          FRA  France      168.0       64.0  1978-03-20  \n",
       "4               England          GBR  France        NaN        NaN  1930-07-25  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olymp = pd.read_excel(\"olympics-data.xlsx\") # to read an excel file \n",
    "\n",
    "olymp.head() # to get the first 5 values of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5f37c-7aa1-489c-a03b-e56cd6941c4c",
   "metadata": {},
   "source": [
    "# Accessing Data with Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb8d17-1113-43d7-9e69-63c9e3f12144",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp.tail() # to get the last 5 values of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3de5b2-4752-47ff-bd46-b124144ed288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access specific values in our data: classic index slicing\n",
    "olymp.loc[0:3] # will get us the file until the 3rd piece of data\n",
    "\n",
    "olymp.loc[0:2, [\"name\", \"NOC\"]] # this format allows us to select specific rows and columns. eg: this piece of code will only grab\n",
    "# the name and the NOC of the players from index 0 to 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f967849-394e-4e60-887e-7228957390aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the iloc allows --> .iloc[row_selection, column_selection] \n",
    "# a key difference to note between loc and iloc is that, with .iloc, the upper index is not inclusive\n",
    "\n",
    "olymp.iloc[0:3, [0, 1, 2, 4, 5]] # NOTICE: how to the 3rd column (born_city) is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5990bf-bc7e-492c-a794-7f1a313c2a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Notice how the indexing, which originally started from 0, has now changed to the the exact data of athlete_id.\n",
    "# that makes each row uniquely identified by an athlete’s ID, \n",
    "# which is helpful for fast lookups, data merging, and removing duplicates based on athletes.\n",
    "\n",
    "olymp.index = olymp['athlete_id']\n",
    "olymp.loc[0] #since index 0 has now been removed, even .loc would not recognize it and show it be a \"KeyError\"\n",
    "olymp.loc[1] # this has replaced loc and the index 1 now shows the data of the athlete \"Jean-François Blanchy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ab3e1-f954-4ef9-aafb-3e9f885ce96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d1b75-576c-496d-a70d-fcab6589ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp.sample(n=6) # .sample(n=k) randomly select rows (or columns), you can see that everytime you run the code, the data changes\n",
    "\n",
    "olymp.sample(frac=0.2) # create a test sample: .sample(frac=k) will get k% of the data, \n",
    "                      # eg: this code will show some random 20% of the whole data\n",
    "\n",
    "olymp.sample(frac=1) # shuffle the dataset\n",
    "\n",
    "olymp.sample(n=2, random_state=1) # keep the same set of random result each time in each random state\n",
    "# this is called reproducibility. ensures that you, and others, get the same result everytime\n",
    "# your random splits stay consistent during model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c677b-dfae-48ed-ab5f-9a06f713b599",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5cc16-cfbc-49cb-8e1c-0590ad093800",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e3887-1ea5-4d0e-a94b-527719444d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08657d-26e2-4cde-9073-99f3195c2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp.sort_values(\"born_date\") # this will sort out values based on the date of birth in an increasing order\n",
    "\n",
    "olymp.sort_values(\"born_date\", ascending = False) # this will sort out values based on the date of birth in a decreasing order\n",
    "\n",
    "olymp.sort_values([\"height_cm\", \"born_date\"]) # this will first sort according to the height, and then through their born date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2230d-9418-4b91-af12-feb9e4c0def1",
   "metadata": {},
   "source": [
    "# Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648888a9-abfa-48ce-8e26-04ceb428f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to grab a certain type of data. With .loc, we only see a certain number of data. \n",
    "\n",
    "olymp.loc[olymp['height_cm'] > 200] # to grab the atheletes whose height is more than 200 cm. \n",
    "\n",
    "olymp.loc[olymp['height_cm'] > 200, ['name', 'height_cm']] # will only show the specific columns mentioned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3baee2-de32-4157-9a90-4d6ae5b500b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without .loc, we get to see the whole dataset where the height > 215\n",
    "\n",
    "olymp[olymp['height_cm'] > 215]\n",
    "\n",
    "olymp[(olymp['height_cm'] > 215) & (olymp['born_country'] == 'USA')] # shows two conditions combined with the AND operator. \n",
    "                                             # only the athletes of height > 215 and who were born in the USA will show up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103d6c1-3d30-4ff1-b2cd-04be3a971559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .contains checks whether the data contains the listed input \n",
    "\n",
    "olymp[olymp['name'].str.contains(\"Keith\")] # notice how \"keith\" with a lower case k will fetch us no results. (case-sensitive)\n",
    "\n",
    "olymp[olymp['name'].str.contains(\"Keith|patrick\", case = False)] # checks if the data contains both keith and patrick (using regex)\n",
    "# case = False renders the case sensitivity to be False. Even though, we wrote \"patrick\" , the data still showed \"Patrick\"\n",
    "\n",
    "olymp[olymp['born_country'].isin([\"USA\", \"GBR\"]) & (olymp['name'].str.startswith('John'))] \n",
    "# athletes whose name is John and are from either the USA or the Great Britain\n",
    "\n",
    "# an easier way to filter data:\n",
    "olymp.query('born_country == \"USA\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353c7ed0-c785-43e4-8d3e-1114a61c957d",
   "metadata": {},
   "source": [
    "# Adding/Removing a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da1af0-000d-408f-8e43-7df7461f8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add a column where if the athlete is French, the new column will say so\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "olymp['French?'] = np.where(olymp['born_country'] == \"FRA\", 'French', 'Not French')\n",
    "# we created a column called \"French?\" where if NOC == \"France\", then the new column will say \"French\", otherwise it will say \"Not French\"\n",
    "\n",
    "olymp.head(77)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401f038-46f3-4dc4-be76-8423f781240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a new column where we have the product of each athlete's height and weight (why not?)\n",
    "\n",
    "olymp[\"prod\"] = olymp['height_cm'] * olymp['weight_kg']\n",
    "olymp.head()\n",
    "\n",
    "# lets remove the columns that we just created cause its not like we actually need it\n",
    "rem = ['prod', 'French?']\n",
    "\n",
    "olymp.drop(rem, axis =1, inplace = True)\n",
    "olymp.head()\n",
    "\n",
    "# the examples above were to show that you can use mathetical operations in the creation of new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24591a30-fb6a-4efc-934f-080aec6d878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to rename a column \n",
    "\n",
    "olymp.rename(columns={'NOC': 'Country Represented'}, inplace=True)\n",
    "\n",
    "olymp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc27c7-02d2-4f51-9ed7-0f01c32b5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add two columns that display the first name and last name seperately \n",
    "\n",
    "olymp['first name'] = olymp['name'].str.split(\" \").str[0]\n",
    "\n",
    "olymp['last name'] = olymp['name'].str.split(\" \").str[1]\n",
    "\n",
    "olymp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857853c-5b49-4ddf-b3f6-5dac656fed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you do .info(), you can see how the datatype is an object for born date.  We should make it into a datetime Dtype\n",
    "\n",
    "olymp['born_date'] = pd.to_datetime(olymp['born_date'])\n",
    "\n",
    "olymp.info() # now we can see that the Dtype has been changed from object to datetime64[ns]\n",
    "olymp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1034fc-889b-4692-b786-6045d10f395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .dt works like .str but is for datetime format\n",
    "\n",
    "olymp['born_year'] = olymp['born_date'].dt.year\n",
    "\n",
    "olymp[['name','born_year']] # will only get the name and the year, the rest of the columns will not be shown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f014a-d97c-407f-b61a-470bc01993f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using lambda to create a new category\n",
    "\n",
    "olymp['height_category'] = olymp['height_cm'].apply(lambda x: 'Short' if x < 165 else ('Average' if x < 185 else 'Tall'))\n",
    "\n",
    "olymp.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf0768-5d31-44ba-a09a-481b6009d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(row):\n",
    "    if row['height_cm'] < 175 and row['weight_kg'] < 70:\n",
    "        return \"LightWeight\"\n",
    "\n",
    "    elif row['height_cm'] < 185 and row['weight_kg'] <= 80:\n",
    "        return \"MiddleWeight\"\n",
    "\n",
    "    else:\n",
    "        return \"HeavyWeight\"\n",
    "\n",
    "olymp['Category'] = olymp.apply(categorize, axis =1)\n",
    "\n",
    "olymp.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f9eef-1767-4d53-adf2-489086649c75",
   "metadata": {},
   "source": [
    "# Merging and Concatenating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758f95b-6a8e-485a-90cc-8f889ca18479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the logical OR\n",
    "\n",
    "new = olymp[(olymp['born_region'] == 'New Hampshire') | (olymp['born_city'] == 'San Francisco')] \n",
    "# will get the data of athletes who are either from New Hampshire or San Francisco\n",
    "\n",
    "# using the AND operator\n",
    "old = olymp[(olymp['born_region'] == 'New Hampshire') & (olymp['born_city'] == 'San Francisco')] \n",
    "# since there are no athletes who are from New Hampshire and San Francisco at the same time, there will be no data on this whatsoever\n",
    "\n",
    "new.head()\n",
    "old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0f599-fd9e-447a-a46e-d02f3d3d0476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how can we get the data of atheletes who are from a specific place\n",
    "\n",
    "usa = olymp[olymp['born_country'] == 'USA'].copy()\n",
    "gbr = olymp[olymp['born_country'] == \"GBR\"].copy()\n",
    "\n",
    "usa.head() # will show everyone who is from the USA\n",
    "gbr.head() # will show everyone who is from the Great Britain\n",
    "\n",
    "# how can we merge these two data together so that the file shows us athletes from both, the USA and the GBR, at the same time.\n",
    "\n",
    "new_df = pd.concat([usa, gbr])  # using .concat\n",
    "\n",
    "new_df.head() \n",
    "new_df.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec78c47-2135-4f2e-a1c0-4fcf0bf3f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we have some new raw data that I want to merge with the olympics dataframe\n",
    "\n",
    "results = pd.read_csv('Olymps_results.csv')\n",
    "\n",
    "\n",
    "# lets combine the two data together\n",
    "\n",
    "# since athelete_id is the only thing both the data had in common, we use that. However, both our index is also called \"athlete_id\"\n",
    "# hence, this will show an error \n",
    "\n",
    "# We now have to specify for the files to reset_index \n",
    "if 'athlete_id' in olymp.index.names:\n",
    "    olymp = olymp.reset_index(drop = True)\n",
    "if 'athlete_id' in results.index.names:\n",
    "    result = result.reset_index(drop = True)\n",
    "\n",
    "combined = pd.merge(olymp, results, on = 'athlete_id', how = 'left')\n",
    "\n",
    "combined.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d766b0-68f3-4f7e-92e0-d6a0913e4929",
   "metadata": {},
   "source": [
    "# Handling Null Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b9ce95-75e8-40f0-b75f-874d6dca1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us change the word \"NaN\" to just a dash \"-\"\n",
    "\n",
    "combined = combined.fillna(\"-\") # every data that said NaN beforehand, now says -, much easier to read and comprehend\n",
    "\n",
    "# when working with numbers, we can also use .interpolate that will fill NaN with values based on patterns beside it \n",
    "\n",
    "# to drop the whole row that has Nan values, we can use \n",
    "\n",
    "results.dropna(inplace = True) # notice how the index now starts with and skips some number slots along, we have removed all the data with NaN values\n",
    "# be careful with this one since it drops the entire row, inplace = True makes it permanent\n",
    "\n",
    "\n",
    "results.head(15)\n",
    "\n",
    "combined.head(15) # notice how the changed we implemented above only exist in results dataframe. In \"combined\", we replaced Nan values with \"-\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97892c60-07cb-4a9a-b414-dc0773b50e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the rows that have Nan Values only \n",
    "results[results['team'].isna()] # this will result in nothing since we do not have any data where the team column has a Nan\n",
    "\n",
    "# to get the rows that have no Nan Values whatsoever\n",
    "\n",
    "results[results['team'].notna()] # since there are no nans in our data file, we get our all the rows here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d392e9-d7bf-4692-a419-7779972dc8d6",
   "metadata": {},
   "source": [
    "# Aggregating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348f123-a474-4c1a-8ee3-b60677997803",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "olymp['born_city'].value_counts() # counts the amount of athletes from each city\n",
    "\n",
    "olymp[olymp['born_country'] == 'USA']['born_region'].value_counts().tail(25)  # counts the amount of athletes from each city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6789a-734d-467e-8ec6-37307f512563",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = pd.read_csv('coffee.csv') # for the next examples, let us use another set of data \n",
    "\n",
    "\n",
    "coffee['Price'] = np.where(coffee['Coffee Type'] == 'Espresso', 5.99, 3.99)\n",
    "\n",
    "coffee['Revenue'] = coffee['Units Sold'] * coffee['Price'] \n",
    "# here, I created another column that represents the Revenue\n",
    "\n",
    "coffee.groupby(['Coffee Type'])['Units Sold'].mean()\n",
    "\n",
    "coffee.groupby(['Coffee Type']).agg({'Units Sold' : 'sum', 'Price' : 'mean'})\n",
    " # groups the data by coffee type and shows the sum of the units sold and the average price of each type: using aggregation \n",
    "\n",
    "# using named aggregation \n",
    "coffee.groupby(['Coffee Type']).agg(\n",
    "    sum_sold = ('Units Sold', 'sum'),\n",
    "    average_price = ('Price', 'mean')\n",
    ")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a2a15-d1e7-4abe-95b4-459ed033e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pivot makes it easier to grab information \n",
    "\n",
    "pivot = coffee.pivot(columns='Coffee Type', index = 'Day', values = 'Revenue')\n",
    "\n",
    "pivot.loc['Monday', 'Latte'] # easy to grab monday's latte count or any other specific value\n",
    "\n",
    "pivot.sum() # shows the total revenue (goes through the columns). It can also be written as pivot.sum(axis=0), which is the default setting\n",
    "\n",
    "pivot.sum(axis=1) # goes through rows, so shows the sum of each day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cde8aaf-7125-48aa-8978-fe0c34009b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets aggregate data on our olympics file\n",
    "olymp['born_date'] = pd.to_datetime(olymp['born_date'], errors='coerce')\n",
    "# errors = 'coerce' basically tells pandas \"if you find something that cannot be turned into a date, do not crash and just replace it\n",
    "# with a special missing value \"NaT\".   Now, even if we remove errors ='coerce', the code wont crash since the system has already replaced \n",
    "# spaces with Nat\n",
    "\n",
    "olymp.groupby(olymp['born_date'].dt.year)['name'].count()\n",
    "# groups by born_date and shows how many names are in those years\n",
    "\n",
    "olymp.groupby(olymp['born_date'].dt.year)['name'].count().reset_index().sort_values('name')\n",
    "# groups the data by born_date and shows how many names in those years, turns the results back from series into a dataframe, then sorts them\n",
    "# in an ascending order\n",
    "\n",
    "olymp.groupby(olymp['born_date'].dt.year)['name'].count().reset_index().sort_values('name', ascending = False)\n",
    "# does the same thing as the code above but in an ascending order\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c998d7-211d-462a-a5bf-8a842c1267d5",
   "metadata": {},
   "source": [
    "reset_index() turns that index back into a regular column, which gives you a DataFrame with normal columns instead of grouped index labels.\n",
    "\n",
    "This makes it easier to:\n",
    "\n",
    "Sort by multiple columns\n",
    "Rename columns\n",
    "Save or export the results\n",
    "Merge with other DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe03607-c33b-430b-b25e-460fced17617",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp['born_date'] = pd.to_datetime(olymp['born_date'], errors='coerce')\n",
    "\n",
    "olymp['month_born'] = olymp['born_date'].dt.month\n",
    "olymp['year_born'] = olymp['born_date'].dt.year\n",
    "\n",
    "olymp.groupby([olymp['year_born'], olymp['month_born']])['name'].count().reset_index().sort_values('name')\n",
    "# This code groups the data by both birth year and birth month, counts how many names fall into each (year, month) pair,\n",
    "# converts the result to a DataFrame, and then sorts the rows by the count of names in ascending order.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aa4df7-5e9d-4665-9c35-295bcb51f2d1",
   "metadata": {},
   "source": [
    "# Advanced Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d802f31-d477-4722-88df-a2055690c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee[\"yesterday's Revenue\"] = coffee['Revenue'].shift(2)\n",
    "# .shift() moves values down by 1 row. shift(2) is for 2 rows which makes more sense here given that we have two days for each day\n",
    "\n",
    "# we can also calculate the percentage change in today's revenue and yesterday's revenue\n",
    "\n",
    "coffee['pct_change'] = coffee['Revenue']/coffee[\"yesterday's Revenue\"] *100 \n",
    "#shows the percentage change between \n",
    "\n",
    "coffee "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18f82f-b9f6-41ab-9b03-1d5746264df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  combined['height_rank'] = combined['height_cm'].rank()\n",
    "\n",
    "#  combined.sort_values(['height_rank'], ascending = False) \n",
    "# here, using combined values will not work given that our combined data has a mix of string and float values. Remember, that in our\n",
    "# Combined dataframe, we have replaced all NaN values with \"-\"\n",
    "\n",
    "olymp['height_rank'] = olymp['height_cm'].rank() # ranks the data according to the height of each athlete\n",
    "\n",
    "olymp.sort_values(['height_rank'], ascending = False), # shows the tallest person first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2219ae-a360-493e-be5a-fd1f56aff02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using .cumsum():  cummulative summation \n",
    "\n",
    "coffee['cummulative_rev'] = coffee['Revenue'].cumsum()  # adds a new column that shows the cummulative revenue \n",
    "\n",
    "coffee['3_day_revenue'] = coffee['Units Sold'].rolling(3).sum() \n",
    "# .rolling() is used to view over your data so you can use .sum(), .mean(), .max(), .min()\n",
    "# it returns a rolling object, so we have to follow it with an aggretion function\n",
    "\n",
    "# if we want to check the 3 day revenue only for Lattes, we can:\n",
    "latte = coffee[coffee['Coffee Type'] == 'Latte'].copy()\n",
    "\n",
    "latte['latte_3day'] = latte['Units Sold'].rolling(2).sum()\n",
    "# the number inside of rolling represents \"window\" = number of observations \n",
    "# can also be written as rolling(window = 2)\n",
    "\n",
    "latte # we can now see a column with a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91011bc0-f40c-4505-8f55-62d28b858025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: to check your pandas version \n",
    "\n",
    "pd.__version__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d58f8-c24a-45b8-a169-1a1511c6ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize_max(frame, name = 'None', val = 'None', description = 'Maximum'):\n",
    "    if isinstance(frame, pd.Series):     # if it is a series, \n",
    "        max_ind = frame.idxmax()         # gets the index with the maximum value\n",
    "        max_val = frame[max_ind]         # uses that maximum index to get that maximum value\n",
    "        print(f'{description}: {max_ind} with a value of {max_val}')\n",
    "    else:\n",
    "        # For DataFrame \n",
    "        max_row = frame[val].idxmax()          # gets the row index of the maximum value\n",
    "        max_label = frame.loc[max_row, name]   # gets the label for that row\n",
    "        max_val = frame.loc[max_row, val]      # gets the numerical value for that row\n",
    "        print(f'{description}: {max_label} with a value of {max_val}') \n",
    "    return max_ind, max_val\n",
    "\n",
    "'''\n",
    "frame: either a pandas Series (like event_counts) or DataFrame (like a grouped DataFrame).\n",
    "\n",
    "name: if it’s a DataFrame, this is the column that holds the label (like sport/event name).\n",
    "\n",
    "value: the column with the numeric values you want to find the max of.\n",
    "\n",
    "description: a text string to describe what we are reporting in the sentence.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160b90f-cc7a-4d3a-9957-22e4265ecae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Age_of_Competition'].max()\n",
    "\n",
    "combined.loc[combined['Age_of_Competition'].idxmax(), ['name', 'birth_year', 'year', 'Age_of_Competition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f5d2d-c864-40ec-b29f-a15d211d0774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ba6c8-57d5-4cc0-96ae-d38d318d22bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
